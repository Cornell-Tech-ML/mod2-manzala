debug statements (python)................................................Passed
mixed line ending........................................................Passed
fix requirements.txt.....................................................Passed
trim trailing whitespace.................................................Passed
ruff.....................................................................Passed
ruff-format..............................................................Passed
pyright..................................................................Failed
- hook id: pyright
- exit code: 1

/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_ops.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_ops.py:42:46 - error: Function with declared return type "MapProto" must return value on all code paths
    "None" is incompatible with protocol "MapProto"
      "__call__" is not present (reportReturnType)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_ops.py:57:47 - error: Function with declared return type "(Tensor, Tensor) -> Tensor" must return value on all code paths
    Type "None" is incompatible with type "(Tensor, Tensor) -> Tensor" (reportReturnType)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_ops.py:72:53 - error: Function with declared return type "(Tensor, Tensor) -> Tensor" must return value on all code paths
    Type "None" is incompatible with type "(Tensor, Tensor) -> Tensor" (reportReturnType)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_ops.py:89:10 - error: Function with declared return type "(Tensor, int) -> Tensor" must return value on all code paths
    Type "None" is incompatible with type "(Tensor, int) -> Tensor" (reportReturnType)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:201:22 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:202:35 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:253:12 - error: "aindex" is possibly unbound (reportPossiblyUnboundVariable)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:254:42 - error: "aindex" is possibly unbound (reportPossiblyUnboundVariable)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:255:33 - error: "aindex" is possibly unbound (reportPossiblyUnboundVariable)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:257:46 - error: "aindex" is possibly unbound (reportPossiblyUnboundVariable)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:259:62 - error: "aindex" is possibly unbound (reportPossiblyUnboundVariable)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py:352:17 - error: Argument of type "list[int]" cannot be assigned to parameter "storage" of type "Storage | List[float]" in function "make"
    Type "list[int]" is incompatible with type "Storage | List[float]"
      "list[int]" is incompatible with "ndarray[Any, dtype[float64]]"
      "list[int]" is incompatible with "List[float]"
        Type parameter "_T@list" is invariant, but "int" is not the same as "float"
        Consider switching from "list" to "Sequence" which is covariant (reportArgumentType)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py:17:32 - error: "is_close" is not a known attribute of module "minitorch" (reportAttributeAccessIssue)
13 errors, 0 warnings, 0 informations

(.venv) syedakazmi-shah@Syedas-MBP mod2-manzala % pre-commit run --all
check for added large files..............................................Passed
check for case conflicts.................................................Passed
check docstring is first.................................................Passed
check for merge conflicts................................................Passed
check for broken symlinks............................(no files to check)Skipped
check toml...............................................................Passed
debug statements (python)................................................Passed
mixed line ending........................................................Passed
fix requirements.txt.....................................................Passed
trim trailing whitespace.................................................Passed
ruff.....................................................................Failed
- hook id: ruff
- files were modified by this hook

warning: The top-level linter settings are deprecated in favour of their counterparts in the `lint` section. Please update the following options in `pyproject.toml`:
  - 'fixable' -> 'lint.fixable'
  - 'ignore' -> 'lint.ignore'
  - 'select' -> 'lint.select'
  - 'unfixable' -> 'lint.unfixable'
  - 'extend-per-file-ignores' -> 'lint.extend-per-file-ignores'
warning: `one-blank-line-before-class` (D203) and `no-blank-line-before-class` (D211) are incompatible. Ignoring `one-blank-line-before-class`.
Found 13 errors (13 fixed, 0 remaining).

ruff-format..............................................................Failed
- hook id: ruff-format
- files were modified by this hook

warning: The top-level linter settings are deprecated in favour of their counterparts in the `lint` section. Please update the following options in `pyproject.toml`:
  - 'fixable' -> 'lint.fixable'
  - 'ignore' -> 'lint.ignore'
  - 'select' -> 'lint.select'
  - 'unfixable' -> 'lint.unfixable'
  - 'extend-per-file-ignores' -> 'lint.extend-per-file-ignores'
warning: `one-blank-line-before-class` (D203) and `no-blank-line-before-class` (D211) are incompatible. Ignoring `one-blank-line-before-class`.
1 file reformatted, 18 files left unchanged

pyright..................................................................Failed
- hook id: pyright
- exit code: 1

/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:201:22 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:202:35 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:253:12 - error: "aindex" is possibly unbound (reportPossiblyUnboundVariable)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:254:42 - error: "aindex" is possibly unbound (reportPossiblyUnboundVariable)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:255:33 - error: "aindex" is possibly unbound (reportPossiblyUnboundVariable)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:257:46 - error: "aindex" is possibly unbound (reportPossiblyUnboundVariable)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:259:62 - error: "aindex" is possibly unbound (reportPossiblyUnboundVariable)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py:352:17 - error: Argument of type "list[int]" cannot be assigned to parameter "storage" of type "Storage | List[float]" in function "make"
    Type "list[int]" is incompatible with type "Storage | List[float]"
      "list[int]" is incompatible with "ndarray[Any, dtype[float64]]"
      "list[int]" is incompatible with "List[float]"
        Type parameter "_T@list" is invariant, but "int" is not the same as "float"
        Consider switching from "list" to "Sequence" which is covariant (reportArgumentType)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py:17:32 - error: "is_close" is not a known attribute of module "minitorch" (reportAttributeAccessIssue)
9 errors, 0 warnings, 0 informations

(.venv) syedakazmi-shah@Syedas-MBP mod2-manzala % pre-commit run --all
check for added large files..............................................Passed
check for case conflicts.................................................Passed
check docstring is first.................................................Passed
check for merge conflicts................................................Passed
check for broken symlinks............................(no files to check)Skipped
check toml...............................................................Passed
debug statements (python)................................................Passed
mixed line ending........................................................Passed
fix requirements.txt.....................................................Passed
trim trailing whitespace.................................................Passed
ruff.....................................................................Failed
- hook id: ruff
- files were modified by this hook

warning: The top-level linter settings are deprecated in favour of their counterparts in the `lint` section. Please update the following options in `pyproject.toml`:
  - 'fixable' -> 'lint.fixable'
  - 'ignore' -> 'lint.ignore'
  - 'select' -> 'lint.select'
  - 'unfixable' -> 'lint.unfixable'
  - 'extend-per-file-ignores' -> 'lint.extend-per-file-ignores'
warning: `one-blank-line-before-class` (D203) and `no-blank-line-before-class` (D211) are incompatible. Ignoring `one-blank-line-before-class`.
Found 2 errors (2 fixed, 0 remaining).

ruff-format..............................................................Failed
- hook id: ruff-format
- files were modified by this hook

warning: The top-level linter settings are deprecated in favour of their counterparts in the `lint` section. Please update the following options in `pyproject.toml`:
  - 'fixable' -> 'lint.fixable'
  - 'ignore' -> 'lint.ignore'
  - 'select' -> 'lint.select'
  - 'unfixable' -> 'lint.unfixable'
  - 'extend-per-file-ignores' -> 'lint.extend-per-file-ignores'
warning: `one-blank-line-before-class` (D203) and `no-blank-line-before-class` (D211) are incompatible. Ignoring `one-blank-line-before-class`.
1 file reformatted, 18 files left unchanged

pyright..................................................................Failed
- hook id: pyright
- exit code: 1

/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:202:49 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:203:35 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py:352:17 - error: Argument of type "list[int]" cannot be assigned to parameter "storage" of type "Storage | List[float]" in function "make"
    Type "list[int]" is incompatible with type "Storage | List[float]"
      "list[int]" is incompatible with "ndarray[Any, dtype[float64]]"
      "list[int]" is incompatible with "List[float]"
        Type parameter "_T@list" is invariant, but "int" is not the same as "float"
        Consider switching from "list" to "Sequence" which is covariant (reportArgumentType)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py:17:32 - error: "is_close" is not a known attribute of module "minitorch" (reportAttributeAccessIssue)
4 errors, 0 warnings, 0 informations

(.venv) syedakazmi-shah@Syedas-MBP mod2-manzala % pre-commit run --all
check for added large files..............................................Passed
check for case conflicts.................................................Passed
check docstring is first.................................................Passed
check for merge conflicts................................................Passed
check for broken symlinks............................(no files to check)Skipped
check toml...............................................................Passed
debug statements (python)................................................Passed
mixed line ending........................................................Passed
fix requirements.txt.....................................................Passed
trim trailing whitespace.................................................Passed
ruff.....................................................................Failed
- hook id: ruff
- exit code: 1
- files were modified by this hook

warning: The top-level linter settings are deprecated in favour of their counterparts in the `lint` section. Please update the following options in `pyproject.toml`:
  - 'fixable' -> 'lint.fixable'
  - 'ignore' -> 'lint.ignore'
  - 'select' -> 'lint.select'
  - 'unfixable' -> 'lint.unfixable'
  - 'extend-per-file-ignores' -> 'lint.extend-per-file-ignores'
warning: `one-blank-line-before-class` (D203) and `no-blank-line-before-class` (D211) are incompatible. Ignoring `one-blank-line-before-class`.
minitorch/tensor.py:39:36: F821 Undefined name `Tensor`
   |
37 |     from .tensor_ops import TensorBackend
38 |
39 |     TensorLike = Union[float, int, Tensor]
   |                                    ^^^^^^ F821
   |

Found 3 errors (2 fixed, 1 remaining).

ruff-format..............................................................Failed
- hook id: ruff-format
- files were modified by this hook

warning: The top-level linter settings are deprecated in favour of their counterparts in the `lint` section. Please update the following options in `pyproject.toml`:
  - 'fixable' -> 'lint.fixable'
  - 'ignore' -> 'lint.ignore'
  - 'select' -> 'lint.select'
  - 'unfixable' -> 'lint.unfixable'
  - 'extend-per-file-ignores' -> 'lint.extend-per-file-ignores'
warning: `one-blank-line-before-class` (D203) and `no-blank-line-before-class` (D211) are incompatible. Ignoring `one-blank-line-before-class`.
1 file reformatted, 18 files left unchanged

pyright..................................................................Failed
- hook id: pyright
- exit code: 1

/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:202:49 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:203:35 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py:39:36 - error: "Tensor" is not defined (reportUndefinedVariable)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py:348:17 - error: Argument of type "list[int]" cannot be assigned to parameter "storage" of type "Storage | List[float]" in function "make"
    Type "list[int]" is incompatible with type "Storage | List[float]"
      "list[int]" is incompatible with "ndarray[Any, dtype[float64]]"
      "list[int]" is incompatible with "List[float]"
        Type parameter "_T@list" is invariant, but "int" is not the same as "float"
        Consider switching from "list" to "Sequence" which is covariant (reportArgumentType)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py:17:32 - error: "is_close" is not a known attribute of module "minitorch" (reportAttributeAccessIssue)
5 errors, 0 warnings, 0 informations

(.venv) syedakazmi-shah@Syedas-MBP mod2-manzala % pre-commit run --all
check for added large files..............................................Passed
check for case conflicts.................................................Passed
check docstring is first.................................................Passed
check for merge conflicts................................................Passed
check for broken symlinks............................(no files to check)Skipped
check toml...............................................................Passed
debug statements (python)................................................Passed
mixed line ending........................................................Passed
fix requirements.txt.....................................................Passed
trim trailing whitespace.................................................Passed
ruff.....................................................................Passed
ruff-format..............................................................Passed
pyright..................................................................Failed
- hook id: pyright
- exit code: 1

/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:202:49 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:203:35 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py:352:17 - error: Argument of type "list[int]" cannot be assigned to parameter "storage" of type "Storage | List[float]" in function "make"
    Type "list[int]" is incompatible with type "Storage | List[float]"
      "list[int]" is incompatible with "ndarray[Any, dtype[float64]]"
      "list[int]" is incompatible with "List[float]"
        Type parameter "_T@list" is invariant, but "int" is not the same as "float"
        Consider switching from "list" to "Sequence" which is covariant (reportArgumentType)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py:17:32 - error: "is_close" is not a known attribute of module "minitorch" (reportAttributeAccessIssue)
4 errors, 0 warnings, 0 informations

(.venv) syedakazmi-shah@Syedas-MBP mod2-manzala % pre-commit run --all
check for added large files..............................................Passed
check for case conflicts.................................................Passed
check docstring is first.................................................Passed
check for merge conflicts................................................Passed
check for broken symlinks............................(no files to check)Skipped
check toml...............................................................Passed
debug statements (python)................................................Passed
mixed line ending........................................................Passed
fix requirements.txt.....................................................Passed
trim trailing whitespace.................................................Passed
ruff.....................................................................Failed
- hook id: ruff
- files were modified by this hook

warning: The top-level linter settings are deprecated in favour of their counterparts in the `lint` section. Please update the following options in `pyproject.toml`:
  - 'fixable' -> 'lint.fixable'
  - 'ignore' -> 'lint.ignore'
  - 'select' -> 'lint.select'
  - 'unfixable' -> 'lint.unfixable'
  - 'extend-per-file-ignores' -> 'lint.extend-per-file-ignores'
warning: `one-blank-line-before-class` (D203) and `no-blank-line-before-class` (D211) are incompatible. Ignoring `one-blank-line-before-class`.
Found 1 error (1 fixed, 0 remaining).

ruff-format..............................................................Failed
- hook id: ruff-format
- files were modified by this hook

warning: The top-level linter settings are deprecated in favour of their counterparts in the `lint` section. Please update the following options in `pyproject.toml`:
  - 'fixable' -> 'lint.fixable'
  - 'ignore' -> 'lint.ignore'
  - 'select' -> 'lint.select'
  - 'unfixable' -> 'lint.unfixable'
  - 'extend-per-file-ignores' -> 'lint.extend-per-file-ignores'
warning: `one-blank-line-before-class` (D203) and `no-blank-line-before-class` (D211) are incompatible. Ignoring `one-blank-line-before-class`.
1 file reformatted, 18 files left unchanged

pyright..................................................................Failed
- hook id: pyright
- exit code: 1

/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:124:31 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:125:27 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:127:35 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py:352:17 - error: Argument of type "list[int]" cannot be assigned to parameter "storage" of type "Storage | List[float]" in function "make"
    Type "list[int]" is incompatible with type "Storage | List[float]"
      "list[int]" is incompatible with "ndarray[Any, dtype[float64]]"
      "list[int]" is incompatible with "List[float]"
        Type parameter "_T@list" is invariant, but "int" is not the same as "float"
        Consider switching from "list" to "Sequence" which is covariant (reportArgumentType)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py:17:32 - error: "is_close" is not a known attribute of module "minitorch" (reportAttributeAccessIssue)
5 errors, 0 warnings, 0 informations

(.venv) syedakazmi-shah@Syedas-MBP mod2-manzala % pre-commit run --all
check for added large files..............................................Passed
check for case conflicts.................................................Passed
check docstring is first.................................................Passed
check for merge conflicts................................................Passed
check for broken symlinks............................(no files to check)Skipped
check toml...............................................................Passed
debug statements (python)................................................Passed
mixed line ending........................................................Passed
fix requirements.txt.....................................................Passed
trim trailing whitespace.................................................Passed
ruff.....................................................................Passed
ruff-format..............................................................Failed
- hook id: ruff-format
- files were modified by this hook

warning: The top-level linter settings are deprecated in favour of their counterparts in the `lint` section. Please update the following options in `pyproject.toml`:
  - 'fixable' -> 'lint.fixable'
  - 'ignore' -> 'lint.ignore'
  - 'select' -> 'lint.select'
  - 'unfixable' -> 'lint.unfixable'
  - 'extend-per-file-ignores' -> 'lint.extend-per-file-ignores'
warning: `one-blank-line-before-class` (D203) and `no-blank-line-before-class` (D211) are incompatible. Ignoring `one-blank-line-before-class`.
1 file reformatted, 18 files left unchanged

pyright..................................................................Failed
- hook id: pyright
- exit code: 1

/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:124:30 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:124:67 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:127:39 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py:352:17 - error: Argument of type "list[int]" cannot be assigned to parameter "storage" of type "Storage | List[float]" in function "make"
    Type "list[int]" is incompatible with type "Storage | List[float]"
      "list[int]" is incompatible with "ndarray[Any, dtype[float64]]"
      "list[int]" is incompatible with "List[float]"
        Type parameter "_T@list" is invariant, but "int" is not the same as "float"
        Consider switching from "list" to "Sequence" which is covariant (reportArgumentType)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py:17:32 - error: "is_close" is not a known attribute of module "minitorch" (reportAttributeAccessIssue)
5 errors, 0 warnings, 0 informations

(.venv) syedakazmi-shah@Syedas-MBP mod2-manzala % pre-commit run --all
check for added large files..............................................Passed
check for case conflicts.................................................Passed
check docstring is first.................................................Passed
check for merge conflicts................................................Passed
check for broken symlinks............................(no files to check)Skipped
check toml...............................................................Passed
debug statements (python)................................................Passed
mixed line ending........................................................Passed
fix requirements.txt.....................................................Passed
trim trailing whitespace.................................................Passed
ruff.....................................................................Passed
ruff-format..............................................................Passed
pyright..................................................................Failed
- hook id: pyright
- exit code: 1

/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:124:30 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:124:67 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:127:39 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py:355:17 - error: Argument of type "list[int]" cannot be assigned to parameter "storage" of type "Storage | List[float]" in function "make"
    Type "list[int]" is incompatible with type "Storage | List[float]"
      "list[int]" is incompatible with "ndarray[Any, dtype[float64]]"
      "list[int]" is incompatible with "List[float]"
        Type parameter "_T@list" is invariant, but "int" is not the same as "float"
        Consider switching from "list" to "Sequence" which is covariant (reportArgumentType)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py:17:32 - error: "is_close" is not a known attribute of module "minitorch" (reportAttributeAccessIssue)
5 errors, 0 warnings, 0 informations

(.venv) syedakazmi-shah@Syedas-MBP mod2-manzala % pytest .
=========================================================== test session starts ============================================================
platform darwin -- Python 3.11.2, pytest-8.3.2, pluggy-1.5.0
rootdir: /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala
configfile: pyproject.toml
plugins: hypothesis-6.54.0, env-1.1.3
collected 68 items

tests/test_tensor.py .......................................................xx....                                                   [ 89%]
tests/test_tensor_data.py .x.....                                                                                                    [100%]

====================================================== 65 passed, 3 xfailed in 17.01s ======================================================
(.venv) syedakazmi-shah@Syedas-MBP mod2-manzala % pre-commit run --all
check for added large files..............................................Passed
check for case conflicts.................................................Passed
check docstring is first.................................................Passed
check for merge conflicts................................................Passed
check for broken symlinks............................(no files to check)Skipped
check toml...............................................................Passed
debug statements (python)................................................Passed
mixed line ending........................................................Passed
fix requirements.txt.....................................................Passed
trim trailing whitespace.................................................Passed
ruff.....................................................................Passed
ruff-format..............................................................Passed
pyright..................................................................Failed
- hook id: pyright
- exit code: 1

/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:124:30 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:124:67 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:127:39 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py:355:17 - error: Argument of type "list[int]" cannot be assigned to parameter "storage" of type "Storage | List[float]" in function "make"
    Type "list[int]" is incompatible with type "Storage | List[float]"
      "list[int]" is incompatible with "ndarray[Any, dtype[float64]]"
      "list[int]" is incompatible with "List[float]"
        Type parameter "_T@list" is invariant, but "int" is not the same as "float"
        Consider switching from "list" to "Sequence" which is covariant (reportArgumentType)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py:17:32 - error: "is_close" is not a known attribute of module "minitorch" (reportAttributeAccessIssue)
5 errors, 0 warnings, 0 informations

(.venv) syedakazmi-shah@Syedas-MBP mod2-manzala % python3 -m streamlit run project/app.py -- 2

  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://192.168.1.175:8501

2024-10-21 22:06:19.236 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_
2024-10-21 22:06:21.137 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_
Epoch: 0/500, loss: 0, correct: 0
2024-10-21 22:06:23.132 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_
^C  Stopping...
(.venv) syedakazmi-shah@Syedas-MBP mod2-manzala % pre-commit run --all
check for added large files..............................................Passed
check for case conflicts.................................................Passed
check docstring is first.................................................Passed
check for merge conflicts................................................Passed
check for broken symlinks............................(no files to check)Skipped
check toml...............................................................Passed
debug statements (python)................................................Passed
mixed line ending........................................................Passed
fix requirements.txt.....................................................Passed
trim trailing whitespace.................................................Passed
ruff.....................................................................Passed
ruff-format..............................................................Passed
pyright..................................................................Failed
- hook id: pyright
- exit code: 1

/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:124:30 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:124:67 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:127:39 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py:355:17 - error: Argument of type "list[int]" cannot be assigned to parameter "storage" of type "Storage | List[float]" in function "make"
    Type "list[int]" is incompatible with type "Storage | List[float]"
      "list[int]" is incompatible with "ndarray[Any, dtype[float64]]"
      "list[int]" is incompatible with "List[float]"
        Type parameter "_T@list" is invariant, but "int" is not the same as "float"
        Consider switching from "list" to "Sequence" which is covariant (reportArgumentType)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py:17:32 - error: "is_close" is not a known attribute of module "minitorch" (reportAttributeAccessIssue)
5 errors, 0 warnings, 0 informations

(.venv) syedakazmi-shah@Syedas-MBP mod2-manzala % pre-commit run --all
check for added large files..............................................Passed
check for case conflicts.................................................Passed
check docstring is first.................................................Passed
check for merge conflicts................................................Passed
check for broken symlinks............................(no files to check)Skipped
check toml...............................................................Passed
debug statements (python)................................................Passed
mixed line ending........................................................Passed
fix requirements.txt.....................................................Passed
trim trailing whitespace.................................................Passed
ruff.....................................................................Passed
ruff-format..............................................................Failed
- hook id: ruff-format
- files were modified by this hook

warning: The top-level linter settings are deprecated in favour of their counterparts in the `lint` section. Please update the following options in `pyproject.toml`:
  - 'fixable' -> 'lint.fixable'
  - 'ignore' -> 'lint.ignore'
  - 'select' -> 'lint.select'
  - 'unfixable' -> 'lint.unfixable'
  - 'extend-per-file-ignores' -> 'lint.extend-per-file-ignores'
warning: `one-blank-line-before-class` (D203) and `no-blank-line-before-class` (D211) are incompatible. Ignoring `one-blank-line-before-class`.
1 file reformatted, 18 files left unchanged

pyright..................................................................Failed
- hook id: pyright
- exit code: 1

/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:124:30 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:124:67 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:127:39 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py:355:17 - error: Argument of type "list[int]" cannot be assigned to parameter "storage" of type "Storage | List[float]" in function "make"
    Type "list[int]" is incompatible with type "Storage | List[float]"
      "list[int]" is incompatible with "ndarray[Any, dtype[float64]]"
      "list[int]" is incompatible with "List[float]"
        Type parameter "_T@list" is invariant, but "int" is not the same as "float"
        Consider switching from "list" to "Sequence" which is covariant (reportArgumentType)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py:17:32 - error: "is_close" is not a known attribute of module "minitorch" (reportAttributeAccessIssue)
5 errors, 0 warnings, 0 informations

(.venv) syedakazmi-shah@Syedas-MBP mod2-manzala % pre-commit run --all
check for added large files..............................................Passed
check for case conflicts.................................................Passed
check docstring is first.................................................Passed
check for merge conflicts................................................Passed
check for broken symlinks............................(no files to check)Skipped
check toml...............................................................Passed
debug statements (python)................................................Passed
mixed line ending........................................................Passed
fix requirements.txt.....................................................Passed
trim trailing whitespace.................................................Passed
ruff.....................................................................Passed
ruff-format..............................................................Passed
pyright..................................................................
Failed
- hook id: pyright
- exit code: 1

/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:122:22 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:123:35 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py:355:17 - error: Argument of type "list[int]" cannot be assigned to parameter "storage" of type "Storage | List[float]" in function "make"
    Type "list[int]" is incompatible with type "Storage | List[float]"
      "list[int]" is incompatible with "ndarray[Any, dtype[float64]]"
      "list[int]" is incompatible with "List[float]"
        Type parameter "_T@list" is invariant, but "int" is not the same as "float"
        Consider switching from "list" to "Sequence" which is covariant (reportArgumentType)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py:17:32 - error: "is_close" is not a known attribute of module "minitorch" (reportAttributeAccessIssue)
4 errors, 0 warnings, 0 informations

(.venv) syedakazmi-shah@Syedas-MBP mod2-manzala %
(.venv) syedakazmi-shah@Syedas-MBP mod2-manzala % pre-commit run --all
check for added large files..............................................Passed
check for case conflicts.................................................Passed
check docstring is first.................................................Passed
check for merge conflicts................................................Passed
check for broken symlinks............................(no files to check)Skipped
check toml...............................................................Passed
debug statements (python)................................................Passed
mixed line ending........................................................Passed
fix requirements.txt.....................................................Passed
trim trailing whitespace.................................................Passed
ruff.....................................................................Passed
ruff-format..............................................................Passed
pyright..................................................................Failed
- hook id: pyright
- exit code: 1

/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:122:22 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor_data.py:123:35 - error: "cuda" is not a known attribute of module "numba" (reportAttributeAccessIssue)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/minitorch/tensor.py:355:17 - error: Argument of type "list[int]" cannot be assigned to parameter "storage" of type "Storage | List[float]" in function "make"
    Type "list[int]" is incompatible with type "Storage | List[float]"
      "list[int]" is incompatible with "ndarray[Any, dtype[float64]]"
      "list[int]" is incompatible with "List[float]"
        Type parameter "_T@list" is invariant, but "int" is not the same as "float"
        Consider switching from "list" to "Sequence" which is covariant (reportArgumentType)
/Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py
  /Users/syedakazmi-shah/Documents/Cornell/MLE/mod2-manzala/tests/strategies.py:17:32 - error: "is_close" is not a known attribute of module "minitorch" (reportAttributeAccessIssue)
4 errors, 0 warnings, 0 informations

(.venv) syedakazmi-shah@Syedas-MBP mod2-manzala % python3 -m streamlit run project/app.py -- 2

  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://192.168.1.175:8501

2024-10-21 22:15:55.536 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_
2024-10-21 22:16:07.505 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_
Epoch: 0/500, loss: 0, correct: 0
2024-10-21 22:16:09.099 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_
Epoch: 0/500, loss: 0, correct: 0
2024-10-21 22:16:12.524 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_
Epoch: 0/500, loss: 0, correct: 0
Epoch: 10/500, loss: 34.64855059320463, correct: 26
Epoch: 20/500, loss: 34.62594624380234, correct: 26
Epoch: 30/500, loss: 34.61970307027687, correct: 26
Epoch: 40/500, loss: 34.61799114278705, correct: 26
Epoch: 50/500, loss: 34.617523520613354, correct: 26
Epoch: 60/500, loss: 34.61739604591855, correct: 26
Epoch: 70/500, loss: 34.617361333024256, correct: 26
Epoch: 80/500, loss: 34.61735188554427, correct: 26
Epoch: 90/500, loss: 34.61734931506035, correct: 26
Epoch: 100/500, loss: 34.61734861578546, correct: 26
Epoch: 110/500, loss: 34.61734842556969, correct: 26
Epoch: 120/500, loss: 34.61734837382958, correct: 26
Epoch: 130/500, loss: 34.61734835975621, correct: 26
Epoch: 140/500, loss: 34.61734835592827, correct: 26
Epoch: 150/500, loss: 34.61734835488707, correct: 26
Epoch: 160/500, loss: 34.61734835460387, correct: 26
Epoch: 170/500, loss: 34.61734835452687, correct: 26
Epoch: 180/500, loss: 34.617348354505936, correct: 26
Epoch: 190/500, loss: 34.61734835450022, correct: 26
Epoch: 200/500, loss: 34.61734835449867, correct: 26
Epoch: 210/500, loss: 34.61734835449822, correct: 26
Epoch: 220/500, loss: 34.6173483544981, correct: 26
Epoch: 230/500, loss: 34.61734835449809, correct: 26
Epoch: 240/500, loss: 34.61734835449808, correct: 26
Epoch: 250/500, loss: 34.61734835449809, correct: 26
Epoch: 260/500, loss: 34.61734835449809, correct: 26
Epoch: 270/500, loss: 34.61734835449806, correct: 26
Epoch: 280/500, loss: 34.61734835449807, correct: 26
Epoch: 290/500, loss: 34.61734835449808, correct: 26
Epoch: 300/500, loss: 34.61734835449806, correct: 26
Epoch: 310/500, loss: 34.61734835449807, correct: 26
Epoch: 320/500, loss: 34.61734835449808, correct: 26
Epoch: 330/500, loss: 34.61734835449806, correct: 26
Epoch: 340/500, loss: 34.61734835449808, correct: 26
Epoch: 350/500, loss: 34.61734835449807, correct: 26
Epoch: 360/500, loss: 34.617348354498084, correct: 26
Epoch: 370/500, loss: 34.61734835449808, correct: 26
Epoch: 380/500, loss: 34.61734835449806, correct: 26
Epoch: 390/500, loss: 34.617348354498056, correct: 26
Epoch: 400/500, loss: 34.61734835449809, correct: 26
Epoch: 410/500, loss: 34.61734835449806, correct: 26
Epoch: 420/500, loss: 34.61734835449807, correct: 26
Epoch: 430/500, loss: 34.61734835449807, correct: 26
Epoch: 440/500, loss: 34.617348354498084, correct: 26
Epoch: 450/500, loss: 34.6173483544981, correct: 26
Epoch: 460/500, loss: 34.61734835449806, correct: 26
Epoch: 470/500, loss: 34.61734835449808, correct: 26
Epoch: 480/500, loss: 34.61734835449808, correct: 26
Epoch: 490/500, loss: 34.61734835449808, correct: 26
Epoch: 500/500, loss: 34.61734835449808, correct: 26
Epoch: 0/500, loss: 0, correct: 0
2024-10-21 22:16:44.681 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_
Epoch: 10/500, loss: 34.51054596300179, correct: 26
Epoch: 20/500, loss: 33.84871051005834, correct: 26
Epoch: 30/500, loss: 33.21729493417275, correct: 33
Epoch: 40/500, loss: 32.50839630991236, correct: 36
Epoch: 50/500, loss: 31.63120609165922, correct: 37
Epoch: 60/500, loss: 30.660889391122474, correct: 40
Epoch: 70/500, loss: 29.54745111798376, correct: 41
Epoch: 80/500, loss: 28.25799924863464, correct: 41
Epoch: 90/500, loss: 26.854203765750658, correct: 41
Epoch: 100/500, loss: 25.42717628585326, correct: 40
Epoch: 110/500, loss: 23.98152297208881, correct: 40
Epoch: 120/500, loss: 22.57146187302179, correct: 41
Epoch: 130/500, loss: 21.21225393646318, correct: 42
Epoch: 140/500, loss: 19.962373698299672, correct: 44
Epoch: 150/500, loss: 18.838055149907305, correct: 45
Epoch: 160/500, loss: 17.854163359010425, correct: 46
Epoch: 170/500, loss: 16.92569051321306, correct: 46
Epoch: 180/500, loss: 16.046570344661664, correct: 46
Epoch: 190/500, loss: 15.218183832414685, correct: 46
Epoch: 200/500, loss: 14.470967093321608, correct: 46
Epoch: 210/500, loss: 13.776891117370207, correct: 46
Epoch: 220/500, loss: 13.129666192861148, correct: 46
Epoch: 230/500, loss: 12.52922776522372, correct: 46
Epoch: 240/500, loss: 12.009284873950769, correct: 46
Epoch: 250/500, loss: 11.524732817242999, correct: 46
Epoch: 260/500, loss: 11.07153939026104, correct: 46
Epoch: 270/500, loss: 10.6481916772452, correct: 46
Epoch: 280/500, loss: 10.252253153046341, correct: 46
Epoch: 290/500, loss: 9.88151862557539, correct: 46
Epoch: 300/500, loss: 9.534208190957168, correct: 47
Epoch: 310/500, loss: 9.208600183647011, correct: 47
Epoch: 320/500, loss: 8.903041879329166, correct: 47
Epoch: 330/500, loss: 8.616055327580133, correct: 48
Epoch: 340/500, loss: 8.346106275741276, correct: 48
Epoch: 350/500, loss: 8.091743849336336, correct: 48
Epoch: 360/500, loss: 7.851681569457578, correct: 49
Epoch: 370/500, loss: 7.624735624871469, correct: 49
Epoch: 380/500, loss: 7.413048949805135, correct: 49
Epoch: 390/500, loss: 7.224791962876821, correct: 49
Epoch: 400/500, loss: 7.0499778509740985, correct: 49
Epoch: 410/500, loss: 6.882756766674604, correct: 49
Epoch: 420/500, loss: 6.723587563246244, correct: 49
Epoch: 430/500, loss: 6.571022815100759, correct: 49
Epoch: 440/500, loss: 6.424953725034409, correct: 49
Epoch: 450/500, loss: 6.284450821136381, correct: 49
Epoch: 460/500, loss: 6.1491073565065175, correct: 49
Epoch: 470/500, loss: 6.018540857219173, correct: 50
Epoch: 480/500, loss: 5.892399628445169, correct: 50
Epoch: 490/500, loss: 5.7704055301867285, correct: 50
Epoch: 500/500, loss: 5.652291474415628, correct: 50
^C  Stopping...
(.venv) syedakazmi-shah@Syedas-MBP mod2-manzala % python3 -m streamlit run project/app.py -- 2

  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://192.168.1.175:8501


  A new version of Streamlit is available.

  See what's new at https://discuss.streamlit.io/c/announcements

  Enter the following command to upgrade:
  $ pip install streamlit --upgrade

Epoch: 0/500, loss: 0, correct: 0
Epoch: 0/500, loss: 0, correct: 0
Epoch: 0/500, loss: 0, correct: 0
2024-10-21 22:17:27.623 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_
2024-10-21 22:17:27.785 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_
2024-10-21 22:17:27.888 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_
^[[A^C  Stopping...
(.venv) syedakazmi-shah@Syedas-MBP mod2-manzala % python3 -m streamlit run project/app.py -- 2

  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://192.168.1.175:8501

2024-10-21 22:17:47.761 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_
2024-10-21 22:17:48.008 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_
2024-10-21 22:17:48.225 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_
2024-10-21 22:17:49.453 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_
Epoch: 0/500, loss: 0, correct: 0
2024-10-21 22:17:51.110 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_
Epoch: 10/500, loss: 41.1283069117717, correct: 21
Epoch: 20/500, loss: 39.17183975373808, correct: 21
Epoch: 30/500, loss: 37.78836669086294, correct: 21
Epoch: 40/500, loss: 36.83128878361362, correct: 21
Epoch: 50/500, loss: 36.182493861786284, correct: 21
Epoch: 60/500, loss: 35.74742967158735, correct: 17
Epoch: 70/500, loss: 35.45440705017554, correct: 6
Epoch: 80/500, loss: 35.25261229992243, correct: 24
Epoch: 90/500, loss: 35.108203436525024, correct: 29
Epoch: 100/500, loss: 34.9997378727798, correct: 29
Epoch: 110/500, loss: 34.914099013138475, correct: 29
Epoch: 120/500, loss: 34.843423303890596, correct: 29
Epoch: 130/500, loss: 34.78302027060083, correct: 29
Epoch: 140/500, loss: 34.730063351039846, correct: 29
Epoch: 150/500, loss: 34.68280503304805, correct: 29
Epoch: 160/500, loss: 34.64012097688017, correct: 29
Epoch: 170/500, loss: 34.60125016591567, correct: 29
Epoch: 180/500, loss: 34.56564804309014, correct: 29
Epoch: 190/500, loss: 34.53290344395267, correct: 29
Epoch: 200/500, loss: 34.50269115226991, correct: 29
Epoch: 0/500, loss: 0, correct: 0
Epoch: 10/500, loss: 33.653731219538365, correct: 29
Epoch: 20/500, loss: 31.83638850809329, correct: 29
Epoch: 30/500, loss: 30.777500731491088, correct: 29
Epoch: 40/500, loss: 29.618298556029504, correct: 29
Epoch: 50/500, loss: 28.274890293573126, correct: 29
Epoch: 60/500, loss: 26.76873784152184, correct: 29
Epoch: 70/500, loss: 25.134431702306838, correct: 29
Epoch: 80/500, loss: 23.35343099361594, correct: 41
Epoch: 90/500, loss: 21.546152047359453, correct: 42
Epoch: 10/500, loss: 35.054552061440624, correct: 29
Epoch: 20/500, loss: 34.40692550590667, correct: 29
Epoch: 30/500, loss: 34.16864442593126, correct: 29
Epoch: 40/500, loss: 34.08172653670251, correct: 29
Epoch: 50/500, loss: 34.05008309558621, correct: 29
Epoch: 60/500, loss: 34.03840014246399, correct: 29
Epoch: 70/500, loss: 34.03387314480681, correct: 29
Epoch: 80/500, loss: 34.03190537245642, correct: 29
Epoch: 90/500, loss: 34.030857223264114, correct: 29
Epoch: 100/500, loss: 34.030145980882125, correct: 29
Epoch: 110/500, loss: 34.02956478711868, correct: 29
Epoch: 120/500, loss: 34.029040061493895, correct: 29
Epoch: 130/500, loss: 34.02854541185552, correct: 29
Epoch: 140/500, loss: 34.02807114660382, correct: 29
Epoch: 150/500, loss: 34.02761349004256, correct: 29
Epoch: 160/500, loss: 34.027170769445085, correct: 29
Epoch: 170/500, loss: 34.02674206705523, correct: 29
Epoch: 180/500, loss: 34.02632674327351, correct: 29
Epoch: 190/500, loss: 34.025924267712014, correct: 29
Epoch: 200/500, loss: 34.0255341590506, correct: 29
Epoch: 210/500, loss: 34.025155963354486, correct: 29
Epoch: 220/500, loss: 34.02478924599858, correct: 29
Epoch: 230/500, loss: 34.024433588414155, correct: 29
Epoch: 240/500, loss: 34.024088586555536, correct: 29
Epoch: 250/500, loss: 34.02375384998974, correct: 29
Epoch: 260/500, loss: 34.023429001220734, correct: 29
Epoch: 270/500, loss: 34.02311367511149, correct: 29
Epoch: 280/500, loss: 34.022807518353986, correct: 29
Epoch: 290/500, loss: 34.02251018896982, correct: 29
Epoch: 300/500, loss: 34.02222135583408, correct: 29
Epoch: 310/500, loss: 34.0219406982192, correct: 29
Epoch: 320/500, loss: 34.02166790535819, correct: 29
Epoch: 330/500, loss: 34.02140267602435, correct: 29
Epoch: 340/500, loss: 34.021144718128106, correct: 29
Epoch: 350/500, loss: 34.02089374832916, correct: 29
Epoch: 360/500, loss: 34.02064949166339, correct: 29
Epoch: 370/500, loss: 34.0204116811837, correct: 29
Epoch: 380/500, loss: 34.02018005761439, correct: 29
Epoch: 390/500, loss: 34.01995436901776, correct: 29
Epoch: 400/500, loss: 34.01973437047287, correct: 29
Epoch: 410/500, loss: 34.019519823765606, correct: 29
Epoch: 420/500, loss: 34.019310497089194, correct: 29
Epoch: 430/500, loss: 34.019106164755435, correct: 29
Epoch: 440/500, loss: 34.01890660691481, correct: 29
Epoch: 450/500, loss: 34.01871160928647, correct: 29
Epoch: 460/500, loss: 34.018520962896524, correct: 29
Epoch: 470/500, loss: 34.01833446382424, correct: 29
Epoch: 480/500, loss: 34.01815191295654, correct: 29
Epoch: 490/500, loss: 34.017973115749484, correct: 29
Epoch: 500/500, loss: 34.01779788199684, correct: 29
Epoch: 0/500, loss: 0, correct: 0
Epoch: 10/500, loss: 34.02100687780748, correct: 29
Epoch: 20/500, loss: 34.015079728045684, correct: 29
Epoch: 30/500, loss: 34.01463577966572, correct: 29
Epoch: 40/500, loss: 34.01460267382034, correct: 29
Epoch: 50/500, loss: 34.014600207982596, correct: 29
Epoch: 60/500, loss: 34.01460002437726, correct: 29
Epoch: 70/500, loss: 34.01460001070726, correct: 29
Epoch: 80/500, loss: 34.014600009689545, correct: 29
Epoch: 90/500, loss: 34.01460000961377, correct: 29
Epoch: 100/500, loss: 34.014600009608124, correct: 29
Epoch: 110/500, loss: 34.01460000960773, correct: 29
Epoch: 120/500, loss: 34.01460000960768, correct: 29
Epoch: 130/500, loss: 34.01460000960766, correct: 29
Epoch: 140/500, loss: 34.01460000960765, correct: 29
Epoch: 150/500, loss: 34.01460000960769, correct: 29
Epoch: 160/500, loss: 34.01460000960767, correct: 29
Epoch: 170/500, loss: 34.014600009607655, correct: 29
Epoch: 180/500, loss: 34.01460000960769, correct: 29
Epoch: 190/500, loss: 34.0146000096077, correct: 29
Epoch: 200/500, loss: 34.01460000960766, correct: 29
Epoch: 210/500, loss: 34.01460000960769, correct: 29
Epoch: 220/500, loss: 34.01460000960769, correct: 29
Epoch: 230/500, loss: 34.0146000096077, correct: 29
Epoch: 240/500, loss: 34.01460000960768, correct: 29
Epoch: 250/500, loss: 34.014600009607676, correct: 29
Epoch: 260/500, loss: 34.014600009607676, correct: 29
Epoch: 270/500, loss: 34.014600009607676, correct: 29
Epoch: 280/500, loss: 34.014600009607676, correct: 29
Epoch: 290/500, loss: 34.014600009607676, correct: 29
Epoch: 300/500, loss: 34.014600009607676, correct: 29
Epoch: 310/500, loss: 34.014600009607676, correct: 29
Epoch: 320/500, loss: 34.014600009607676, correct: 29
Epoch: 330/500, loss: 34.014600009607676, correct: 29
Epoch: 340/500, loss: 34.014600009607676, correct: 29
Epoch: 350/500, loss: 34.014600009607676, correct: 29
Epoch: 360/500, loss: 34.014600009607676, correct: 29
Epoch: 0/500, loss: 0, correct: 0
Epoch: 10/500, loss: 33.931785063103746, correct: 29
Epoch: 20/500, loss: 32.843502727381356, correct: 29
Epoch: 30/500, loss: 24.690644641268673, correct: 39
Epoch: 40/500, loss: 15.092474512228494, correct: 49
Epoch: 50/500, loss: 11.700386579960917, correct: 48
Epoch: 60/500, loss: 19.609909520359253, correct: 43
Epoch: 70/500, loss: 5.3657261682121264, correct: 49
Epoch: 80/500, loss: 3.9052286011795987, correct: 49
Epoch: 90/500, loss: 3.1147806411869015, correct: 49
Epoch: 100/500, loss: 2.6333403722447617, correct: 49
Epoch: 110/500, loss: 2.4537382660762135, correct: 49
Epoch: 120/500, loss: 4.393161955681984, correct: 49
Epoch: 130/500, loss: 9.449390749513388, correct: 47
Epoch: 140/500, loss: 2.16247118486205, correct: 50
Epoch: 150/500, loss: 1.745956074423281, correct: 50
Epoch: 160/500, loss: 1.4695946086005456, correct: 50
Epoch: 170/500, loss: 1.2652575726789999, correct: 50
Epoch: 180/500, loss: 1.1063446722678782, correct: 50
Epoch: 190/500, loss: 0.9797268885222458, correct: 50
Epoch: 200/500, loss: 0.8751080263020096, correct: 50
Epoch: 210/500, loss: 0.7910656014056496, correct: 50
Epoch: 220/500, loss: 0.721100419815244, correct: 50
Epoch: 230/500, loss: 0.6661994841830481, correct: 50
Epoch: 240/500, loss: 0.6157083802932783, correct: 50
Epoch: 250/500, loss: 0.572176297108658, correct: 50
Epoch: 260/500, loss: 0.5347323894963653, correct: 50
Epoch: 270/500, loss: 0.5012798373582068, correct: 50
Epoch: 280/500, loss: 0.47167730401080404, correct: 50
Epoch: 290/500, loss: 0.444813387940651, correct: 50
Epoch: 300/500, loss: 0.42083496975319873, correct: 50
Epoch: 310/500, loss: 0.39932749319542127, correct: 50
Epoch: 320/500, loss: 0.3798871712303191, correct: 50
Epoch: 330/500, loss: 0.36261494823689644, correct: 50
Epoch: 340/500, loss: 0.3466048487117077, correct: 50
Epoch: 350/500, loss: 0.3297142185208827, correct: 50
Epoch: 360/500, loss: 0.31590303410797826, correct: 50
Epoch: 370/500, loss: 0.30420356083980093, correct: 50
Epoch: 380/500, loss: 0.2909941300460551, correct: 50
Epoch: 390/500, loss: 0.2800941001825366, correct: 50
Epoch: 400/500, loss: 0.27060014736963744, correct: 50
Epoch: 410/500, loss: 0.26011573253368353, correct: 50
Epoch: 420/500, loss: 0.25182417998224743, correct: 50
Epoch: 430/500, loss: 0.24263027516967828, correct: 50
Epoch: 440/500, loss: 0.23532843739734685, correct: 50
Epoch: 450/500, loss: 0.22721473800173425, correct: 50
Epoch: 460/500, loss: 0.22073779439263805, correct: 50
Epoch: 470/500, loss: 0.21353470682212494, correct: 50
Epoch: 480/500, loss: 0.20778318478763105, correct: 50
Epoch: 490/500, loss: 0.2013726952956526, correct: 50
Epoch: 500/500, loss: 0.1962647556446954, correct: 50